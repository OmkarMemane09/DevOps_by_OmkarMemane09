# Introduction to Kubernetes
*Kubernetes (K8s) is an open-source container orchestration platform used to automate deployment, scaling, and management of containerized apps. It was originally built by Google and is now maintained by the Cloud Native Computing Foundation (CNCF).*

## Key Features

```bash

-Automated Scheduling: Places containers on optimal nodes.
-Self-Healing: Restarts or replaces failed containers automatically.
-Horizontal Scaling: Scales apps up or down based on load.
-Service Discovery & Load Balancing: Exposes containers as network services and balances traffic.
-Storage Orchestration: Automatically mounts local/cloud storage.
-Rolling Updates & Rollbacks: Deploy updates with zero downtime and revert on failure.
-Secret and Config Management: Securely manages sensitive data and app configs.
-Health Monitoring: Monitors containers and nodes, helping keep the cluster running smoothly.

```
### Example Use Case:
```bash
Imagine a web app running in 10 containers across multiple servers. Kubernetes will:
Distribute containers evenly across available servers.
Auto-replace crashed containers.
Route traffic to available containers, avoiding downtime.
```
## Why We Need an Orchestration Tool
Manually managing a few containers may be simple, but at scale:

Scaling: Tedious to start/stop containers for demand changes.

Load Balancing: Hard to distribute user traffic yourself.

High Availability: Slow to detect and restart failed containers.

Networking: Complex to manage multi-host networking.

Zero-downtime Updates: Difficult to update without affecting users.

Example:
If 100 containers run on 5 servers, and 1 server fails, you need to spot the problem, restart containers elsewhere, and update load balancers. Kubernetes automates all this.

Why Kubernetes?
Open Source: Free & vendor-neutral.
Extensible: Integrates with plugins/APIs.
Scalable & Portable: Handles large workloads anywhere (cloud/on-premises).
Self-healing & Resilient: Recovers from failures autonomously.
Rich Ecosystem: Supported by community & cloud providers.

Architecture of Kubernetes

<img width="1183" height="753" alt="image" src="https://github.com/user-attachments/assets/f2e45541-9b3a-4e53-bf7b-cf2fab098f35" />

Kubernetes follows a master-worker pattern:

Control Plane (Master): Makes global cluster decisions and manages cluster state.

Worker Nodes: Run containerized applications (Pods begin here).

Control Plane Components
API Server (kube-apiserver): Entry point for all cluster operations. Handles requests from kubectl, automations, and other components.

etcd: Stores cluster state/configuration as a consistent key-value store.

Controller Manager (kube-controller-manager): Ensures desired state (e.g., enough pods running), triggers scheduling for fixes.

Scheduler (kube-scheduler): Assigns new pods to suitable nodes.

Cloud Controller Manager: (Optional) Connects Kubernetes to cloud-specific features/plumbing.

Worker Node Components
Kubelet: Ensures specified containers/pods are running and healthy on its node.

Kube-Proxy: Manages network rules and routes traffic to pods.

Container Runtime: Actually runs containers (e.g., Docker, containerd).

Key Kubernetes Objects & Resources
Pod: Smallest deployable unit; contains one or more containers.

Service: Stable network endpoint for accessing pods.

Deployment: Manages rollouts/updates of pods (for stateless apps).

ReplicaSet: Ensures a set number of pod copies are running.

StatefulSet/DaemonSet/Job/CronJob: Specialized workload types.

ConfigMap/Secret: Stores configs or sensitive data securely.

Namespace: Logical cluster partition for isolation and organization.

Ingress: Manages HTTP(S) routing.

NetworkPolicy: Controls pod network communication.

Kubernetes Architecture Summary
Control Plane (Master Node): Manages cluster state and schedules workloads.

Worker Node: Runs application containers in pods.

Pods: The app's running units (containers live here).

Additional Components: ConfigMaps, Secrets, Namespaces, Ingress, etc.

Example Workflow
User defines desired state (e.g., kubectl apply -f app.yaml).

API Server receives request, stores intent in etcd.

Scheduler picks worker node for new pod(s).

Kubelet starts pod(s) as per spec.

Controller Manager keeps required number of pods running.

Kube-Proxy manages networking, routes traffic as needed.

Pod Lifecycle Phases
Pending: Pod accepted, waiting to be scheduled.

Running: All containers in the pod active.

Succeeded: Containers exited successfully.

Failed: Containers exited with error(s).

Unknown: State can't be determined (node/network issue).

Cluster Creation Methods
Tool/Service	Description	Use Case
Minikube	Runs a cluster locally via VM/Docker	Learning, local dev
Kind	Runs cluster in Docker containers	CI/CD, quick tests
kubeadm	Bootstraps cluster manually	Custom prod setups
EKS	AWS-managed Kubernetes	AWS Production
GKE	Google-managed Kubernetes	GCP Production
AKS	Azure-managed Kubernetes	Azure Production
Introduction to Pods and Services
Pods
The smallest deployable object in Kubernetes. A pod runs one or more containers sharing network and storage resources.

Lifecycle: Pending → Running → Succeeded/Failed → Terminated

Use Cases:

Single container app (web server, backend, etc.)

Multiple tight-coupled containers (logging, proxy sidecars)

Services
Provides stable networking for pods. Types:

Service Type	Accessible From	Use Cases	Access Format
ClusterIP	Inside cluster only	Internal traffic	http://backend:8080
NodePort	From node IP & port	Demos/test external	http://<node-ip>:30080
LoadBalancer	From Internet	Prod/public access	http://<public-ip>
Main Container vs Sidecar Container
Main Container: Runs the main app (e.g., backend API).

Sidecar Container: Runs support tasks (e.g., log collector, proxy, config reload).

Both share resources in the pod but have separate roles.

Run First Pod Using kubectl
bash
# Create a basic nginx pod:
kubectl run nginx-pod --image=nginx --restart=Never
# --image: Chooses the container image
# --restart=Never: Ensures it's a plain pod, not a Deployment

# View pods
kubectl get pods

# See details
yaml
tkubectl describe pod nginx-pod
Expose Pod Using kubectl expose
bash
# Expose as NodePort service:
kubectl expose pod nginx-pod --type=NodePort --port=80
 --type=NodePort: Opens a static port outside the cluster
 --port: Tells what port nginx listens on

# View services
kubectl get svc

# Access at http://<NodeIP>:<NodePort>
In-Depth: kubectl Usage
Common Commands
bash
# View Kubernetes resources
kubectl get pods
kubectl get svc
kubectl get nodes

# Delete specific pod
yaml
kubectl delete pod <pod-name>

# See logs
kubectl logs <pod-name>

# Get shell in pod
kubectl exec -it <pod-name> -- /bin/bash

# Describe pod
yaml
kubectl describe pod <pod-name>
Additional Best Practices
Use Namespaces: Organize environments (dev, prod, test)

Use Labels & Selectors: Tag/identify resources for targeting and grouping

ConfigMap & Secret: Store configs and sensitive data outside pod spec

Requests & Limits: Define CPU/memory to prevent resource overuse

Persistent Volumes: Use PV/PVC for persistent storage (databases, stateful apps)

Network Policies: Enforce traffic rules between pods

RBAC: Use role-based access controls for security

Monitoring & Logging: Integrate with tools like Prometheus, Grafana, EFK/ELK for cluster insight

Use Ingress Controller: For advanced HTTP routing (domain/path based)
