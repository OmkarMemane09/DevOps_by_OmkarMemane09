#  Horizontal Pod Autoscaler (HPA) 

## ğŸ“Œ What is HPA?
The **Horizontal Pod Autoscaler (HPA)** is a Kubernetes mechanism that automatically increases or decreases the number of Pod replicas in a Deployment, ReplicaSet, or StatefulSet based on **real-time resource usage metrics**.

Its primary goal is to keep applications responsive and stable under different workloads by adjusting capacity automatically.

---
<img width="908" height="397" alt="image" src="https://github.com/user-attachments/assets/e03a7ffb-91a3-4264-b68a-7bf299aaf73f" />

## ğŸ“Œ Why Do We Need HPA?
Applications typically experience fluctuating traffic:
- High traffic â†’ more CPU/Memory usage â†’ need more pods  
- Low traffic â†’ low usage â†’ fewer pods
  
Manually scaling pods is inefficient.  
HPA solves this by **automatically scaling based on metrics** such as:
- CPU utilization
- Memory usage
- Custom metrics (Prometheus)
- External metrics (CloudWatch, SQS queue length, etc.)
  
## ğŸ“Œ HPA Limitations

- Cannot scale workloads that **must remain 1 replica**  
  (DaemonSet, Jobs, CronJobs, static pods)

- Requires **resource requests** (CPU/Memory)  
  Otherwise HPA cannot calculate percentages.

- Slow scale-down due to stabilization window (default 5 min).

---
## ğŸ“Œ VPA vs HPA â€” Core Differences

| Feature | HPA | VPA |
|--------|-----|-----|
| Scaling Type | Horizontal (add pods) | Vertical (resize pods) |
| Works Best For | Stateless, scalable apps | Stateful apps, memory-bound apps |
| Uses | CPU%, Memory%, Custom metrics | Historical & live usage |
| Pod Restart Required | âŒ No | âœ… Yes |
| Resource Optimization | Medium | Excellent |
| Handles Spikes | Fast | Slow |
---
## ğŸ“Œ 1. Create Kubernetes Manifests
This guide demonstrates how to deploy an application, expose it using a Service, enable CPU-based Horizontal Pod Autoscaling (HPA), install the Metrics Server, and test autoscaling using a load generator.

###  1.1 Create Deployment Manifest

```bash
nano deployment.yaml
```

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: demo
spec:
  selector:
    matchLabels:
      app: demo
  template:
    metadata:
      labels:
        app: demo
    spec:
      containers:
        - name: demo
          image: registry.k8s.io/hpa-example:latest
          ports:
            - containerPort: 80
          resources:
            requests:
              cpu: 500m
```
###  1.2 Create Service Manifest
```bash
nano service.yaml
```
*Creates a Service manifest to expose the application inside the cluster.*
```yaml
apiVersion: v1
kind: Service
metadata:
  name: demo
spec:
  ports:
    - port: 80
  selector:
    app: demo
```

### 1.3 Create HPA Manifest
```bash
nano hpa.yaml
```
*Creates the HPA configuration using CPU utilization as the scaling metric.*
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: demo
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: demo
  minReplicas: 3
  maxReplicas: 9
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 50
```

## ğŸ“Œ 2. Apply Kubernetes Resources

### 2.1 Apply Deployment
```bash
kubectl apply -f deployment.yaml
```
*Deploys your application workload into Kubernetes.*

### 2.2 Apply Service
```bash
kubectl apply -f service.yaml
```
*Creates a Service for internal communication between Pods and load generator.*

### 2.3 Apply HPA Config
```bash
kubectl apply -f hpa.yaml
```
*Registers your Horizontal Pod Autoscaler with K8s.
Initially, CPU may show as <unknown> until Metrics Server is running.*

### ğŸ“Œ 3. Install Metrics Server (Required for HPA)

**Metrics Server provides resource usage (CPU/Memory) for Pods & Nodes.**

### 3.1 Install Metrics Server
```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```
*Installs the official Metrics Server release manifest from Kubernetes SIGs repo.*

### 3.2 Patch Metrics Server (Required on KillerKoda)
```bash
kubectl patch deployment metrics-server -n kube-system \
  --type='json' \
  -p='[{"op":"add","path":"/spec/template/spec/containers/0/args/-","value":"--kubelet-insecure-tls"}]'
```
*Adds --kubelet-insecure-tls so Metrics Server can read metrics from kubelet
(needed because KillerKoda uses self-signed certificates).*

### 3.3 Restart Metrics Server
```bash
kubectl rollout restart deployment metrics-server -n kube-system
```
*Applies the patch by forcing a restart of the Metrics Server Pods.*

### 3.4 Verify Metrics Server is Running
```bash
kubectl get pods -n kube-system
```

**Expected output:**
```metrics-server-xxxxx   Running```

## ğŸ“Œ 4. Verify Metrics Availability

### 4.1 Show Node Metrics
```bash
kubectl top nodes
```
*Displays CPU & Memory usage of all nodes. (Requires Metrics Server)*

### 4.2 Show Pod Metrics
```bash
kubectl top pods
```
*Displays CPU/Memory usage of pods â€” confirms Metrics Server is functional.*

## ğŸ“Œ 5. Generate Load to Trigger HPA

### 5.1 Run Load Generator Pod
```bash
kubectl run -it --rm load-test \
--image=busybox:1.28 --restart=Never \
-- /bin/sh -c "while sleep 0.01; do wget -q -O- http://demo; done"
```
*Creates a temporary BusyBox pod that continuously hits the app service, increasing CPU load.*
```bash
This triggers HPA scaling.

-it â†’ interactive terminal

--rm â†’ deletes pod after exit

wget -q -O- â†’ silently fetches the service endpoint
```
## ğŸ“Œ 6. Observe HPA Behavior

### 6.1 Check HPA Scaling Status
```bash
kubectl get hpa
```
*Shows CPU utilization and number of replicas currently scaled by HPA.*

### 6.2 Check Deployment Scaling
```bash
kubectl get deployment
```
*Displays replica count of your deployment, which will increase under load.*

## ğŸ‰ Final Result
```
After load generation:
HPA observes rising CPU utilization
Replicas scale from minReplicas to maxReplicas
When load stops, replicas gradually scale down
HPA is now fully functional!
```
